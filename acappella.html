---
layout: page
title: Acappella
subtitle: A dataset for audio-visual singing voice separation
---
<p style='text-align: justify;'>

    <i>Acappella</i> comprises of around <b>46 hours </b>
    of <i>a cappella</i> solo singing videos sourced from YouTube,
    sampled across different singers and languages.
    These YouTube videos were all publicly available at the time of the dataset creation.
    The idea behind <i>Acappella</i> is to provide a large-scale dataset
    to train audio-visual models for singing voice separation.
    Each video recording has been manually selected to exclude parts
    of the videos that do not satisfy any of the following characteristics:
    single frontal face view without occlusions, minimal background
    noise, no beatboxing, no snapping fingers, songs with lyrics
    (e.g. we avoid humming and yodelling).
    The dataset comprises of <b>1493</b> different videos in total spanning four language categories:
    English, Spanish, Hindi and Others. The dataset statistics are shown in the figures below.
</p>

<div class="row">
    <div class="col-sm-6">
        <img src="../img/violinplot.png">
    </div>
    <div class="col-sm-6">
        <img src="../img/barplot.png">
    </div>
</div>

<p style='text-align: justify;'>

</p>



We also selected some demo videos and created a montage with ground-truth samples in order to evaluate the algorithm.  
In-depth details will be provided subject to paper acceptance.  



